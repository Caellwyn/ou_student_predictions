{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_timeseries_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9VolUYYPoMyLkZpxBx6MO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqzFRYjEdOxQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from seaborn import heatmap\n",
        "\n",
        "from keras import Input\n",
        "from keras import backend as K\n",
        "from keras import regularizers, optimizers\n",
        "from keras.layers import Dense, Dropout, ConvLSTM2D, Conv1D, \\\n",
        "AveragePooling1D, LSTM, GRU\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, \\\n",
        "roc_auc_score, plot_precision_recall_curve, plot_roc_curve, \\\n",
        "plot_confusion_matrix, confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join(os.pardir))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "try:\n",
        "    from src.functions import add_model, test_model, get_timeseries_table\n",
        "except:\n",
        "    from functions import add_model, test_model, get_timeseries_table"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy5TWGhKoa3r"
      },
      "source": [
        "The below is thanks to [dokondr](https://stackoverflow.com/questions/45411902/how-to-use-f1-score-with-keras-model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyTr0M5foZc8"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "\n",
        "    # Count positive samples.\n",
        "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\n",
        "    # If there are no true samples, fix the F1 score at 0.\n",
        "    if c3 == 0:\n",
        "        return 0\n",
        "\n",
        "    # How many selected items are relevant?\n",
        "    precision = c1 / c2\n",
        "\n",
        "    # How many relevant items are selected?\n",
        "    recall = c1 / c3\n",
        "\n",
        "    # Calculate f1_score\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1_score "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8yTbGIPdXjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "edf6af0c-a164-4dae-b8c5-454ec458434a"
      },
      "source": [
        "df = get_timeseries_table(prediction_window=135, \n",
        "                          binary_labels=True, \n",
        "                          one_hot_modules=True)\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assess_submitted_1</th>\n",
              "      <th>assess_score_1</th>\n",
              "      <th>assess_submitted_2</th>\n",
              "      <th>assess_score_2</th>\n",
              "      <th>assess_submitted_3</th>\n",
              "      <th>assess_score_3</th>\n",
              "      <th>assess_submitted_4</th>\n",
              "      <th>assess_score_4</th>\n",
              "      <th>assess_submitted_5</th>\n",
              "      <th>assess_score_5</th>\n",
              "      <th>assess_submitted_6</th>\n",
              "      <th>assess_score_6</th>\n",
              "      <th>assess_submitted_7</th>\n",
              "      <th>assess_score_7</th>\n",
              "      <th>assess_submitted_8</th>\n",
              "      <th>assess_score_8</th>\n",
              "      <th>sum_activities_-25</th>\n",
              "      <th>sum_click_-25</th>\n",
              "      <th>activities_x_clicks_-25</th>\n",
              "      <th>sum_activities_-24</th>\n",
              "      <th>sum_click_-24</th>\n",
              "      <th>activities_x_clicks_-24</th>\n",
              "      <th>sum_activities_-23</th>\n",
              "      <th>sum_click_-23</th>\n",
              "      <th>activities_x_clicks_-23</th>\n",
              "      <th>sum_activities_-22</th>\n",
              "      <th>sum_click_-22</th>\n",
              "      <th>activities_x_clicks_-22</th>\n",
              "      <th>sum_activities_-21</th>\n",
              "      <th>sum_click_-21</th>\n",
              "      <th>activities_x_clicks_-21</th>\n",
              "      <th>sum_activities_-20</th>\n",
              "      <th>sum_click_-20</th>\n",
              "      <th>activities_x_clicks_-20</th>\n",
              "      <th>sum_activities_-19</th>\n",
              "      <th>sum_click_-19</th>\n",
              "      <th>activities_x_clicks_-19</th>\n",
              "      <th>sum_activities_-18</th>\n",
              "      <th>sum_click_-18</th>\n",
              "      <th>activities_x_clicks_-18</th>\n",
              "      <th>...</th>\n",
              "      <th>sum_click_124</th>\n",
              "      <th>activities_x_clicks_124</th>\n",
              "      <th>sum_activities_125</th>\n",
              "      <th>sum_click_125</th>\n",
              "      <th>activities_x_clicks_125</th>\n",
              "      <th>sum_activities_126</th>\n",
              "      <th>sum_click_126</th>\n",
              "      <th>activities_x_clicks_126</th>\n",
              "      <th>sum_activities_127</th>\n",
              "      <th>sum_click_127</th>\n",
              "      <th>activities_x_clicks_127</th>\n",
              "      <th>sum_activities_128</th>\n",
              "      <th>sum_click_128</th>\n",
              "      <th>activities_x_clicks_128</th>\n",
              "      <th>sum_activities_129</th>\n",
              "      <th>sum_click_129</th>\n",
              "      <th>activities_x_clicks_129</th>\n",
              "      <th>sum_activities_130</th>\n",
              "      <th>sum_click_130</th>\n",
              "      <th>activities_x_clicks_130</th>\n",
              "      <th>sum_activities_131</th>\n",
              "      <th>sum_click_131</th>\n",
              "      <th>activities_x_clicks_131</th>\n",
              "      <th>sum_activities_132</th>\n",
              "      <th>sum_click_132</th>\n",
              "      <th>activities_x_clicks_132</th>\n",
              "      <th>sum_activities_133</th>\n",
              "      <th>sum_click_133</th>\n",
              "      <th>activities_x_clicks_133</th>\n",
              "      <th>sum_activities_134</th>\n",
              "      <th>sum_click_134</th>\n",
              "      <th>activities_x_clicks_134</th>\n",
              "      <th>final_result</th>\n",
              "      <th>module_AAA</th>\n",
              "      <th>module_BBB</th>\n",
              "      <th>module_CCC</th>\n",
              "      <th>module_DDD</th>\n",
              "      <th>module_EEE</th>\n",
              "      <th>module_FFF</th>\n",
              "      <th>module_GGG</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>registration</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAA2013J11391</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAA2013J28400</th>\n",
              "      <td>3.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>418.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAA2013J31604</th>\n",
              "      <td>-2.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAA2013J32885</th>\n",
              "      <td>7.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAA2013J38053</th>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGG2014J691787</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGG2014J692171</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGG2014J693046</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGG2014J695877</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGG2014J698019</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24005 rows Ã— 504 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                assess_submitted_1  assess_score_1  ...  module_FFF  module_GGG\n",
              "registration                                        ...                        \n",
              "AAA2013J11391                 -1.0            78.0  ...           0           0\n",
              "AAA2013J28400                  3.0            70.0  ...           0           0\n",
              "AAA2013J31604                 -2.0            72.0  ...           0           0\n",
              "AAA2013J32885                  7.0            69.0  ...           0           0\n",
              "AAA2013J38053                  0.0            79.0  ...           0           0\n",
              "...                            ...             ...  ...         ...         ...\n",
              "GGG2014J691787                 0.0             0.0  ...           0           1\n",
              "GGG2014J692171                 0.0             0.0  ...           0           1\n",
              "GGG2014J693046                 0.0             0.0  ...           0           1\n",
              "GGG2014J695877                 0.0             0.0  ...           0           1\n",
              "GGG2014J698019                 0.0             0.0  ...           0           1\n",
              "\n",
              "[24005 rows x 504 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvzyNQR-oXj5"
      },
      "source": [
        "X = df.drop(columns='final_result')\n",
        "y = df['final_result']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111, test_size=.1)\n",
        "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, random_state=111, test_size=.1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ngKd7HZWDi",
        "outputId": "35a98a37-a714-47fb-9928-a44a42b45f50"
      },
      "source": [
        "len(X.columns)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "503"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jybgl0OfZrUk",
        "outputId": "45d5f54a-9e71-4b8f-9742-8f496fa32869"
      },
      "source": [
        "categoricals = [502, 501, 500, 499, 498, 497, 496]\n",
        "smotenc = SMOTENC(categoricals, random_state=111)\n",
        "os_X_train, os_y_train = smotenc.fit_resample(X_train, y_train)\n",
        "os_X_t, os_y_t = smotenc.fit_resample(X_t, y_t)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfTKcEOEkt-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf6ea3a-6ea3-4c12-bd32-f534d9686379"
      },
      "source": [
        "l1 = 1e-4\n",
        "l2 = 1e-3\n",
        "bias = 1e-4\n",
        "dropout500=0.4\n",
        "dropout300=0.2\n",
        "dropout200=0.2\n",
        "\n",
        "model1 = keras.Sequential()\n",
        "model1.add(Input((X.shape[1])))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = optimizers.Adamax()\n",
        "\n",
        "model1.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#class_balance = num(pass) / num(fail).  Use this to weight class 0.\n",
        "class_balance = sum(y_t == 1) / sum(y_t == 0)\n",
        "\n",
        "model1.fit(X_t, y_t,\n",
        "           batch_size = 200,\n",
        "           epochs = 50,\n",
        "           validation_data=(X_val, y_val),\n",
        "        #    class_weight = {1: 1.0,\n",
        "        #                    0: class_balance}\n",
        "           )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "98/98 [==============================] - 5s 15ms/step - loss: 14.8957 - accuracy: 0.6078 - val_loss: 13.8702 - val_accuracy: 0.6654\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 13.6850 - accuracy: 0.6397 - val_loss: 13.2830 - val_accuracy: 0.6784\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 13.1219 - accuracy: 0.6378 - val_loss: 12.8057 - val_accuracy: 0.6789\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 12.6538 - accuracy: 0.6522 - val_loss: 12.3774 - val_accuracy: 0.6090\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 12.2203 - accuracy: 0.6783 - val_loss: 11.9652 - val_accuracy: 0.5405\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 11.8109 - accuracy: 0.6757 - val_loss: 11.5548 - val_accuracy: 0.5280\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 11.3954 - accuracy: 0.6847 - val_loss: 11.1492 - val_accuracy: 0.5164\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 10.9788 - accuracy: 0.6851 - val_loss: 10.7421 - val_accuracy: 0.4984\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 10.5623 - accuracy: 0.6882 - val_loss: 10.3268 - val_accuracy: 0.5123\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 10.1413 - accuracy: 0.6900 - val_loss: 9.8889 - val_accuracy: 0.5534\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 9.7043 - accuracy: 0.7010 - val_loss: 9.4500 - val_accuracy: 0.5882\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 9.2640 - accuracy: 0.7071 - val_loss: 8.9716 - val_accuracy: 0.6483\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 8.8066 - accuracy: 0.7252 - val_loss: 8.5115 - val_accuracy: 0.6821\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 8.3493 - accuracy: 0.7401 - val_loss: 8.0317 - val_accuracy: 0.7274\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 7.8837 - accuracy: 0.7518 - val_loss: 7.5800 - val_accuracy: 0.7381\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 7.4265 - accuracy: 0.7598 - val_loss: 7.1062 - val_accuracy: 0.7566\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 6.9647 - accuracy: 0.7673 - val_loss: 6.6630 - val_accuracy: 0.7510\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 6.5074 - accuracy: 0.7760 - val_loss: 6.1817 - val_accuracy: 0.7700\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 6.0546 - accuracy: 0.7771 - val_loss: 5.7688 - val_accuracy: 0.7575\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5.6113 - accuracy: 0.7815 - val_loss: 5.3802 - val_accuracy: 0.7242\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5.1841 - accuracy: 0.7779 - val_loss: 4.9465 - val_accuracy: 0.7432\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 4.7636 - accuracy: 0.7832 - val_loss: 4.4715 - val_accuracy: 0.7746\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 4.3635 - accuracy: 0.7779 - val_loss: 4.0720 - val_accuracy: 0.7811\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 3.9619 - accuracy: 0.7898 - val_loss: 3.7164 - val_accuracy: 0.7770\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 3.6014 - accuracy: 0.7852 - val_loss: 3.3538 - val_accuracy: 0.7844\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 3.2520 - accuracy: 0.7904 - val_loss: 3.0289 - val_accuracy: 0.7839\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.9354 - accuracy: 0.7890 - val_loss: 2.7248 - val_accuracy: 0.7904\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.6395 - accuracy: 0.7885 - val_loss: 2.4421 - val_accuracy: 0.7894\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.3689 - accuracy: 0.7888 - val_loss: 2.1959 - val_accuracy: 0.7825\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.1196 - accuracy: 0.7905 - val_loss: 1.9642 - val_accuracy: 0.7867\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.8999 - accuracy: 0.7972 - val_loss: 1.7737 - val_accuracy: 0.7871\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.7054 - accuracy: 0.7913 - val_loss: 1.5844 - val_accuracy: 0.7918\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5280 - accuracy: 0.7967 - val_loss: 1.4278 - val_accuracy: 0.7932\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3750 - accuracy: 0.8003 - val_loss: 1.2930 - val_accuracy: 0.7927\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2526 - accuracy: 0.7952 - val_loss: 1.1757 - val_accuracy: 0.7918\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1270 - accuracy: 0.8021 - val_loss: 1.0784 - val_accuracy: 0.7899\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0471 - accuracy: 0.7925 - val_loss: 1.0021 - val_accuracy: 0.7820\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9582 - accuracy: 0.7997 - val_loss: 0.9245 - val_accuracy: 0.7876\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8833 - accuracy: 0.8053 - val_loss: 0.8672 - val_accuracy: 0.7890\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8412 - accuracy: 0.7963 - val_loss: 0.8185 - val_accuracy: 0.7853\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7892 - accuracy: 0.7981 - val_loss: 0.7859 - val_accuracy: 0.7918\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7464 - accuracy: 0.8060 - val_loss: 0.7430 - val_accuracy: 0.7978\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7103 - accuracy: 0.8060 - val_loss: 0.7156 - val_accuracy: 0.7918\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6789 - accuracy: 0.8121 - val_loss: 0.7011 - val_accuracy: 0.7885\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6703 - accuracy: 0.8106 - val_loss: 0.6851 - val_accuracy: 0.7918\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6514 - accuracy: 0.8085 - val_loss: 0.6752 - val_accuracy: 0.7853\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6333 - accuracy: 0.8115 - val_loss: 0.6609 - val_accuracy: 0.7908\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6218 - accuracy: 0.8119 - val_loss: 0.6530 - val_accuracy: 0.7918\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6087 - accuracy: 0.8178 - val_loss: 0.6470 - val_accuracy: 0.7881\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6107 - accuracy: 0.8134 - val_loss: 0.6467 - val_accuracy: 0.7857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef97a8b310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb45z1hpAW8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a1727536-5003-4e6b-a092-b1248807306c"
      },
      "source": [
        "yhat = np.around(model1.predict(X_val)).astype(int)[:,0]\n",
        "\n",
        "confusion = confusion_matrix(y_val, yhat, normalize='true')\n",
        "heatmap(confusion, cmap='Greens', annot=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef532889d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4PzNv2LVpYt",
        "outputId": "3b6b40bf-b4ed-489f-a461-c81bfc8379b7"
      },
      "source": [
        "l1 = 1e-4\n",
        "l2 = 1e-3\n",
        "bias = 1e-4\n",
        "dropout500=0.4\n",
        "dropout300=0.2\n",
        "dropout200=0.2\n",
        "\n",
        "model1 = keras.Sequential()\n",
        "model1.add(Input((X.shape[1])))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(500, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout500))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(300, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout300))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "model1.add(Dropout(rate=dropout200))\n",
        "model1.add(Dense(200, activation='relu', \n",
        "                 kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n",
        "                 bias_regularizer=regularizers.l2(bias)))\n",
        "\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# optimizer = optimizers.SGD(learning_rate=.1)\n",
        "optimizer = keras.optimizers.Adam(learning_rate = .001)\n",
        "\n",
        "model1.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "class_balance = sum(y_t == 1) / sum(y_t == 0)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.0001)\n",
        "\n",
        "model1.fit(os_X_t, os_y_t,\n",
        "           batch_size = 200,\n",
        "           epochs = 50,\n",
        "           validation_data=(X_val, y_val),\n",
        "           callbacks = [reduce_lr]\n",
        "           )"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 4s 13ms/step - loss: 14.4721 - accuracy: 0.5726 - val_loss: 11.3858 - val_accuracy: 0.4419\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 10.5479 - accuracy: 0.6366 - val_loss: 8.5340 - val_accuracy: 0.6599\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 7.8429 - accuracy: 0.7307 - val_loss: 6.2508 - val_accuracy: 0.7635\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 5.7749 - accuracy: 0.7495 - val_loss: 4.6747 - val_accuracy: 0.6988\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 4.2385 - accuracy: 0.7664 - val_loss: 3.4261 - val_accuracy: 0.7367\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 3.1470 - accuracy: 0.7631 - val_loss: 2.5863 - val_accuracy: 0.7469\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 2.3772 - accuracy: 0.7695 - val_loss: 1.9775 - val_accuracy: 0.7649\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 1.8489 - accuracy: 0.7687 - val_loss: 1.5743 - val_accuracy: 0.7807\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.4743 - accuracy: 0.7723 - val_loss: 1.3333 - val_accuracy: 0.7441\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.2278 - accuracy: 0.7733 - val_loss: 1.1259 - val_accuracy: 0.7608\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0381 - accuracy: 0.7871 - val_loss: 0.9822 - val_accuracy: 0.7640\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9264 - accuracy: 0.7719 - val_loss: 0.9090 - val_accuracy: 0.7534\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8404 - accuracy: 0.7748 - val_loss: 0.7890 - val_accuracy: 0.7862\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.7710 - accuracy: 0.7765 - val_loss: 0.7470 - val_accuracy: 0.7807\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.7284 - accuracy: 0.7772 - val_loss: 0.7158 - val_accuracy: 0.7862\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6877 - accuracy: 0.7818 - val_loss: 0.7039 - val_accuracy: 0.7719\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6640 - accuracy: 0.7805 - val_loss: 0.6578 - val_accuracy: 0.7918\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.7845 - val_loss: 0.6539 - val_accuracy: 0.7834\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6262 - accuracy: 0.7777 - val_loss: 0.6360 - val_accuracy: 0.7770\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6107 - accuracy: 0.7891 - val_loss: 0.6244 - val_accuracy: 0.7774\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6002 - accuracy: 0.7857 - val_loss: 0.6451 - val_accuracy: 0.7686\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5969 - accuracy: 0.7891 - val_loss: 0.6287 - val_accuracy: 0.7765\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5883 - accuracy: 0.7884 - val_loss: 0.6111 - val_accuracy: 0.7756\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5820 - accuracy: 0.7906 - val_loss: 0.6090 - val_accuracy: 0.7807\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5810 - accuracy: 0.7930 - val_loss: 0.6292 - val_accuracy: 0.7765\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5770 - accuracy: 0.7962 - val_loss: 0.6115 - val_accuracy: 0.7862\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5733 - accuracy: 0.7924 - val_loss: 0.6266 - val_accuracy: 0.7719\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.8001 - val_loss: 0.6107 - val_accuracy: 0.7797\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5680 - accuracy: 0.7956 - val_loss: 0.6091 - val_accuracy: 0.7830\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.5512 - accuracy: 0.8027 - val_loss: 0.6029 - val_accuracy: 0.7802\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.5392 - accuracy: 0.8040 - val_loss: 0.6105 - val_accuracy: 0.7723\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5192 - accuracy: 0.8180 - val_loss: 0.5967 - val_accuracy: 0.7774\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5205 - accuracy: 0.8142 - val_loss: 0.5994 - val_accuracy: 0.7779\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5153 - accuracy: 0.8191 - val_loss: 0.5957 - val_accuracy: 0.7807\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5145 - accuracy: 0.8206 - val_loss: 0.5981 - val_accuracy: 0.7779\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5123 - accuracy: 0.8183 - val_loss: 0.6119 - val_accuracy: 0.7737\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5029 - accuracy: 0.8237 - val_loss: 0.6108 - val_accuracy: 0.7677\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4976 - accuracy: 0.8302 - val_loss: 0.6110 - val_accuracy: 0.7756\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5010 - accuracy: 0.8275 - val_loss: 0.6277 - val_accuracy: 0.7635\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5010 - accuracy: 0.8254 - val_loss: 0.6075 - val_accuracy: 0.7751\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4807 - accuracy: 0.8342 - val_loss: 0.6156 - val_accuracy: 0.7709\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4870 - accuracy: 0.8298 - val_loss: 0.6054 - val_accuracy: 0.7760\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4855 - accuracy: 0.8356 - val_loss: 0.6047 - val_accuracy: 0.7751\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4832 - accuracy: 0.8368 - val_loss: 0.6103 - val_accuracy: 0.7737\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4790 - accuracy: 0.8384 - val_loss: 0.6049 - val_accuracy: 0.7779\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4798 - accuracy: 0.8335 - val_loss: 0.6225 - val_accuracy: 0.7658\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4771 - accuracy: 0.8367 - val_loss: 0.6168 - val_accuracy: 0.7746\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4783 - accuracy: 0.8358 - val_loss: 0.6215 - val_accuracy: 0.7696\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4732 - accuracy: 0.8412 - val_loss: 0.6135 - val_accuracy: 0.7700\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4717 - accuracy: 0.8406 - val_loss: 0.6202 - val_accuracy: 0.7737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef55fed6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "D6V-3IqOWqBU",
        "outputId": "6ce4a972-5fda-4ed0-a784-35bc6beeb406"
      },
      "source": [
        "yhat = np.around(model1.predict(X_val)).astype(int)[:,0]\n",
        "\n",
        "confusion = confusion_matrix(y_val, yhat, normalize='true')\n",
        "heatmap(confusion, cmap='Greens', annot=True)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef56f00090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4v_AJcSaVua"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}